# CS370_Pirate-Intelligent-Agent
The field of artificial intelligence offers a plethora of possibilities when applied to games and simulations. This project aims to develop an intelligent agent, a pirate, that navigates a maze environment to find treasure using the principles of Deep Q-Learning.


Briefly explain the work that you did on this project: What code were you given? What code did you create yourself?

In the "Pirate Intelligent Agent: Deep Q-Learning Based Treasure Hunt" project, I was tasked with developing an intelligent agent that could navigate a maze environment to find treasure. The challenge was to determine an optimal path from the start to the treasure while avoiding obstacles. While the foundational code for the maze environment was provided, I developed the Deep Q-Learning algorithm from scratch, incorporating elements like the epsilon-greedy strategy and neural network architecture for the agent's decision-making process.

Connect your learning from throughout this course to the larger field of computer science:

What do computer scientists do and why does it matter?
Computer scientists develop solutions to complex problems using computational principles. In the context of this project, we employed AI to solve a game simulation, showcasing how these principles can have tangible, real-world applications. The work matters because it can be scaled or adapted to larger challenges, such as navigation systems or robotics.

How do I approach a problem as a computer scientist?
I begin by understanding the problem statement thoroughly. In this case, navigating a maze efficiently. Then, I research suitable algorithms or methods, like Deep Q-learning, that can be applied. Through iterative coding, testing, and optimization, I aim to develop an effective solution. The use of metrics, such as win rate and loss, allows me to gauge and refine the model's performance.

What are my ethical responsibilities to the end user and the organization?
As a computer scientist, I must ensure that the solutions I develop are fair, and transparent, and do not introduce biases. For this project, it meant ensuring the intelligent agent operated as intended, without any unforeseen behaviors that could mislead users or stakeholders.


